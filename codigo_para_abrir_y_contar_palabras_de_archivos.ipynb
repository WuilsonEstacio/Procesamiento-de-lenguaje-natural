{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codigo para abrir y contar  palabras de archivos.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0+XVto829H7Z1OmfCPlaP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WuilsonEstacio/Procesamiento-de-lenguaje-natural/blob/main/codigo_para_abrir_y_contar_palabras_de_archivos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-_svjMdXyjo",
        "outputId": "bf9c94c7-b76d-4b09-99d3-7e0b13c39e65"
      },
      "source": [
        "# para leer un archivo\n",
        "archivo = open('/content/Hash.txt','r')\n",
        "for linea in archivo:\n",
        "  print(linea)\n",
        "archivo.close()\n",
        "\n",
        "archivo=\"/content/Hash.txt\"\n",
        "with open(archivo) as f:\n",
        "  text=f.read()\n",
        "\n",
        "for char in \"abcdefghijklmnopqrsrtuvwxyz\":\n",
        "  perc=100*count_char(text, char)/len(text)\n",
        "  print(\"{0}-{1}%\".format(char, round(perc, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Usted puede interponer demanda ante los jueces civiles del \n",
            "\n",
            "circuito que conocen en primera instancia de los \n",
            "\n",
            "procesos contenciosos de mayor cuantía por responsabilidad médica. \n",
            "\n",
            "Pretendiendo el pago de los perjuicios materiales  \n",
            "a-6.52%\n",
            "b-0.43%\n",
            "c-5.65%\n",
            "d-5.65%\n",
            "e-12.17%\n",
            "f-0.0%\n",
            "g-0.43%\n",
            "h-0.0%\n",
            "i-6.96%\n",
            "j-0.87%\n",
            "k-0.0%\n",
            "l-3.48%\n",
            "m-2.17%\n",
            "n-6.52%\n",
            "o-7.83%\n",
            "p-3.48%\n",
            "q-0.43%\n",
            "r-5.22%\n",
            "s-6.52%\n",
            "r-5.22%\n",
            "t-3.91%\n",
            "u-2.61%\n",
            "v-0.43%\n",
            "w-0.0%\n",
            "x-0.0%\n",
            "y-0.43%\n",
            "z-0.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx2Sz9J4IoJu",
        "outputId": "5ea8aff4-4c2c-42b8-a66b-db171b26cbc4"
      },
      "source": [
        "# Which of the following is the correct regular expression to extract all the phone numbers from the following chunk of text:\n",
        "import re\n",
        "patter = '[(]\\d{3}[)]\\s\\d{3}[-]\\d{4}'\n",
        "print(patter)\n",
        "re.findall(patter,archivo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(]\\d{3}[)]\\s\\d{3}[-]\\d{4}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKZJgbD1LdnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91cd6b66-6162-40ad-bf68-9f4862a20e60"
      },
      "source": [
        "#con este codigo se puede contar las palabras que hay en un archivo\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def count_char(text, char):\n",
        "  count=0\n",
        "  for c in text:\n",
        "    if c == char:\n",
        "      count +=1\n",
        "  return count\n",
        "\n",
        "# con esto cambiamos el contenido de Hash.txt y modificamos el escrito y lo guardamos\n",
        "file =open(\"/content/Hash.txt\",\"w\")\n",
        "file.write(\"\"\" Usted puede interponer demanda ante los jueces civiles del \n",
        "circuito que conocen en primera instancia de los \n",
        "procesos contenciosos de mayor cuantía por responsabilidad médica. \n",
        "Pretendiendo el pago de los perjuicios materiales  \"\"\")\n",
        "file.close()\n",
        "filename=\"20-12-2020.txt\"\n",
        "with open('/content/Hash.txt') as f:\n",
        "  text=f.read()\n",
        "\n",
        "for char in \"abcdefghijklmnopqrsrtuvwxyz\":\n",
        "  perc=100*count_char(text, char)/len(text)\n",
        "  print(\"{0}-{1}%\".format(char, round(perc, 2)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a-6.52%\n",
            "b-0.43%\n",
            "c-5.65%\n",
            "d-5.65%\n",
            "e-12.17%\n",
            "f-0.0%\n",
            "g-0.43%\n",
            "h-0.0%\n",
            "i-6.96%\n",
            "j-0.87%\n",
            "k-0.0%\n",
            "l-3.48%\n",
            "m-2.17%\n",
            "n-6.52%\n",
            "o-7.83%\n",
            "p-3.48%\n",
            "q-0.43%\n",
            "r-5.22%\n",
            "s-6.52%\n",
            "r-5.22%\n",
            "t-3.91%\n",
            "u-2.61%\n",
            "v-0.43%\n",
            "w-0.0%\n",
            "x-0.0%\n",
            "y-0.43%\n",
            "z-0.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwDHHwQvLq69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "51934b78-7540-49ec-96b4-18c0278b652f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "filename=input(\"ingrese el nombre del archivo: \")\n",
        "with open( filename ) as f:\n",
        "  text=f.read()\n",
        "\n",
        "filename = open(\"20-12-2020.txt\",\"r\")\n",
        "for linea in filename.readlines():\n",
        "#str=filename.read()\n",
        "#print(len(str))\n",
        "  print(linea)\n",
        "filename.close()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ingrese el nombre del archivo: mas\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c53db6e676a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ingrese el nombre del archivo: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mas'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g7sVEz-iGOL",
        "outputId": "eecb179b-6d5b-44ca-b9f7-21a579030781"
      },
      "source": [
        "# importamos librerias\n",
        "import nltk \n",
        "nltk.download('cess_esp') # para preeentener\n",
        "from nltk.corpus import cess_esp as cess\n",
        "from nltk import UnigramTagger as ut # etiquetador por unigramas\n",
        "from nltk import BigramTagger as bt # etiquetador por bigramas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]   Package cess_esp is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mil60Oaoinow",
        "outputId": "ed5579f8-a085-4b35-c918-166b82d4708b"
      },
      "source": [
        "# https://www.delftstack.com/es/howto/python-pandas/how-to-load-data-from-txt-with-pandas/#read_csv-m%25C3%25A9todo-para-cargar-los-datos-del-archivo-de-texto\n",
        "# una forma de leer el archivo con pandas\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\n",
        "    '/content/Hash.txt', sep=\" \",header=None)\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             0             1        2           3   ...       7        8    9   10\n",
            "0           NaN         Usted    puede  interponer  ...   jueces  civiles  del NaN\n",
            "1      circuito           que  conocen          en  ...      los      NaN  NaN NaN\n",
            "2      procesos  contenciosos       de       mayor  ...  médica.      NaN  NaN NaN\n",
            "3  Pretendiendo            el     pago          de  ...      NaN      NaN  NaN NaN\n",
            "\n",
            "[4 rows x 11 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRRjcj2xigyY",
        "outputId": "1591393c-d4ee-4ebe-9d40-13d41f1248e6"
      },
      "source": [
        "# leemos el archivo\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "archivo = open('/content/Hash.txt','r')\n",
        "for linea in archivo:\n",
        "  print(linea)\n",
        "archivo.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Usted puede interponer demanda ante los jueces civiles del \n",
            "\n",
            "circuito que conocen en primera instancia de los \n",
            "\n",
            "procesos contenciosos de mayor cuantía por responsabilidad médica. \n",
            "\n",
            "Pretendiendo el pago de los perjuicios materiales  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyf34sIOn71q"
      },
      "source": [
        "# pip install win_unicode_console"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0uBB92pmVNl"
      },
      "source": [
        "# Utilizado para vizualizar caracteres correctamente en consola\n",
        "import codecs\n",
        "import win_unicode_console\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        " \n",
        "# Abrimos el archivo\n",
        "archivo = codecs.open('/content/Hash.txt', 'r', encoding='utf-8')\n",
        "texto = \"\"\n",
        "\n",
        "#Almacenamos el texto en una variable\n",
        "for linea in archivo:\n",
        "    linea = linea.strip()\n",
        "    texto = texto + \" \" + linea"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo4bIWEUoRk_",
        "outputId": "93b10db8-d35d-4d64-df63-8f8fa3ab6a01"
      },
      "source": [
        "text = word_tokenize(texto)\n",
        "nltk.pos_tag(text) # etiquetado aplicado al text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Usted', 'VBN'),\n",
              " ('puede', 'NN'),\n",
              " ('interponer', 'NN'),\n",
              " ('demanda', 'NN'),\n",
              " ('ante', 'IN'),\n",
              " ('los', 'JJ'),\n",
              " ('jueces', 'NNS'),\n",
              " ('civiles', 'NNS'),\n",
              " ('del', 'VBP'),\n",
              " ('circuito', 'JJ'),\n",
              " ('que', 'NN'),\n",
              " ('conocen', 'NN'),\n",
              " ('en', 'IN'),\n",
              " ('primera', 'NN'),\n",
              " ('instancia', 'NN'),\n",
              " ('de', 'IN'),\n",
              " ('los', 'FW'),\n",
              " ('procesos', 'JJ'),\n",
              " ('contenciosos', 'NN'),\n",
              " ('de', 'IN'),\n",
              " ('mayor', 'FW'),\n",
              " ('cuantía', 'NN'),\n",
              " ('por', 'NN'),\n",
              " ('responsabilidad', 'NN'),\n",
              " ('médica', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Pretendiendo', 'NNP'),\n",
              " ('el', 'JJ'),\n",
              " ('pago', 'NN'),\n",
              " ('de', 'IN'),\n",
              " ('los', 'FW'),\n",
              " ('perjuicios', 'NNS'),\n",
              " ('materiales', 'NNS')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_yXRO9qoHgo"
      },
      "source": [
        "#Realizamos el Tokenizing con Sent_Tokenize() a cada una de las sentencias del texto\n",
        "# tokens = sent_tokenize(texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0kqDhtMn5g6"
      },
      "source": [
        "# **Test** \n",
        "\n",
        "1.\n",
        "Si tenemos un dataset etiquetado donde la categoría adjetivo (ADJ) aparece un total de 500 veces entre todos los tokens, y de esas veces solamente la palabra \"noble\" le corresponde 200 veces, entonces podemos decir que:\n",
        "\n",
        "La probabilidad de emisión P(noble|ADJ) = 40%\n",
        "\n",
        "2.\n",
        "El proceso mediante el cual un Modelo Markoviano Latente determina la secuencia de etiquetas más probable para una secuencia de palabras es:\n",
        "\n",
        "Usando el algoritmo de Viterbi para obtener la categoría más probable, palabra por palabra.\n",
        "\n",
        "3.\n",
        "Dada una cadena de texto text en español, el procedimiento para asignar las etiquetas gramaticales con Stanza es a partir de un objeto nlp(text), donde:\n",
        "\n",
        "nlp = stanza.Pipeline('es', processors='tokenize,pos')\n",
        "\n",
        "4.\n",
        "La ingeniería de atributos se usa para:\n",
        "\n",
        "Construir atributos particulares de palabras y textos que permitan dar un input más apropiado a un modelo de clasificación.\n",
        "\n",
        "5.\n",
        "El problema de clasificación de texto pertenece a la categoría de Machine Learning supervisado porque:\n",
        "\n",
        "Durante el entrenamiento, el modelo tiene conocimiento de las etiquetas correctas que debería predecir.\n",
        "\n",
        "6.\n",
        "En un modelo de clasificación por categorías gramaticales, el algoritmo de Viterbi se usa para:\n",
        "\n",
        "El proceso de decodificación: encontrar la secuencia de etiquetas más probable.\n",
        "\n",
        "7.\n",
        "En un Modelo Markoviano Latente se necesitan los siguientes ingredientes:\n",
        "\n",
        "Matrices de transición, emisión y distribución inicial de estados.\n",
        "\n",
        "8.\n",
        "En un problema de clasificación de emails entre SPAM y HAM, la métrica de recall tiene la siguiente interpretación:\n",
        "\n",
        "De todos los correos que realmente son SPAM, la fracción que el modelo logró identificar.\n",
        "\n",
        "9.\n",
        "Para entrenar un clasificador de Naive Bayes en NLTK, se escribe en Python:\n",
        "\n",
        "nltk.NaiveBayesClassifier.train(data)\n",
        "\n",
        "10.\n",
        "Si tienes un modelo de clasificación binaria que luego de entrenarlo, obtienes que el número de verdaderos positivos es 200 y el número de falsos positivos es 120, entonces la métrica de precisión de dicho modelo tiene un valor de:\n",
        "\n",
        "200/320\n",
        "\n",
        "11.\n",
        "Un algoritmo general de clasificación de texto:\n",
        "\n",
        "Es un algoritmo de Machine Learning supervisado.\n",
        "\n",
        "12.\n",
        "El tokenizador por defecto en NLTK para el idioma inglés es:\n",
        "\n",
        "punkt\n",
        "\n",
        "13.\n",
        "En una cadena de Markov se necesitan los siguientes elementos:\n",
        "\n",
        "Matriz de transiciones y distribución inicial de estados.\n",
        "\n",
        "14.\n",
        "Entrenar un Modelo Markoviano Latente significa:\n",
        "\n",
        "Calcular las matrices de probabilidad de transición y emisión con un corpus de textos.\n",
        "\n",
        "15.\n",
        "Una de las siguientes no es una categoría de ambigüedades del lenguaje:\n",
        "\n",
        "Vectorial\n",
        "\n",
        "16.\n",
        "El suavizado de Laplace se usa en un algoritmo de clasificación con el objetivo de:\n",
        "\n",
        "Evitar probabilidades nulas y denominadores iguales a cero.\n",
        "\n",
        "17.\n",
        "El clasificador de Naive Bayes es:\n",
        "\n",
        "Un clasificador probabilístico que hace uso de la regla de Bayes.\n",
        "\n",
        "18.\n",
        "En la frase: \"mi hermano es muy noble\", la palabra noble hace referencia a:\n",
        "\n",
        "Un adjetivo\n",
        "\n",
        "19.\n",
        "Con Naive Bayes preferimos hacer cálculos en espacio logarítmico para:\n",
        "\n",
        "Evitar productos de números demasiado pequeños para la precisión de máquina.\n",
        "\n",
        "20.\n",
        "En un modelo MEMM:\n",
        "\n",
        "El proceso de decodificación es similar al de un HMM, y por lo tanto se puede usar un tipo de algoritmo de Viterbi.\n",
        "\n",
        "21.\n",
        "El accuracy de entrenamiento de un modelo se calcula como:\n",
        "\n",
        "(número de veces que el modelo predice la categoría correcta) / (total de datos usados para entrenamiento)\n",
        "\n",
        "22.\n",
        "Si tenemos una cadena de Markov para describir las probabilidades de transición en cuanto al clima de un dia para otro, y observamos la siguiente secuencia de estados día tras día: (frío, frío, caliente, frío, tibio, caliente, tibio, frío), entonces la probabilidad de transición P(caliente|frío) es:\n",
        "\n",
        "50%\n",
        "\n",
        "23.\n",
        "\n",
        "En un Modelo Markoviano Latente, el problema de calcular la secuencia de etiquetas más probable se expresa con la siguiente expresión matemática:\n",
        "\n",
        "$${\\arg \\max}_{(t^n)}\\prod_i P(w_i \\vert t_i)P(t_i \\vert t_{i-1})$$\n",
        "\n",
        "24.\n",
        "Para un modelo de clasificación de palabras con Naive Bayes en NLTK, debemos entrenar el algoritmo usando:\n",
        "\n",
        "nltk.NaiveBayesClassifier.train(train_set) donde usamos una funcion que extrae atributos llamada atributos() y:\n",
        "\n",
        "train_set = [(atributos(palabra), categoría de la palabra), ...]\n",
        "\n",
        "25.\n",
        "Dada una cadena de texto text en inglés, el procedimiento para asignar las etiquetas gramaticales con NLTK es:\n",
        "\n",
        "nltk.pos_tag(word_tokenize(text))"
      ]
    }
  ]
}